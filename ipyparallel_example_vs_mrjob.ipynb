{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Word Count with ipyparallel, MRJob, and single CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Count Example with ipyparallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Starting engines\n",
    "```\n",
    "!ipcluster nbextension enable # doesn't seem to work anymore\n",
    "!ipython profile create mycluster --parallel\n",
    "!ipcluster start --n=4 --profile=myclster # --daemon=True doesn't seem to work, have to do it on Terminal\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ipyparallel as ipp\n",
    "\n",
    "\n",
    "# wait 10 seconds before running this cell after starting the cluster\n",
    "client = ipp.Client()\n",
    "print(client.ids)\n",
    "load_balanced_view = client.load_balanced_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 5/5 [00:06<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# pass function into load_balanced view\n",
    "from glob import glob\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "def word_counter(file_name):\n",
    "    from collections import Counter # can pass in all imports\n",
    "    counter = Counter()\n",
    "    with open(file_name) as f:\n",
    "        for line in f:\n",
    "            counter.update(line.lower().split())\n",
    "        return counter\n",
    "\n",
    "num_pieces = 5\n",
    "!split --number=l/{num_pieces} encyclopedia_britannica.txt temp_file.\n",
    "\n",
    "async = load_balanced_view.map(word_counter, \n",
    "    glob(\"/Users/Eugene/Desktop/Repos/ipyparallel-vs-MRJob/temp_file*\"),\n",
    "    ordered=False, chunksize=1)\n",
    "\n",
    "global_counter1 = Counter() \n",
    "for engine_result in tqdm(async):\n",
    "    global_counter1.update(engine_result)\n",
    "    \n",
    "!rm temp_file*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# decorate with load_balanced_view\n",
    "@load_balanced_view.parallel(ordered=False, chunksize=1)\n",
    "def word_counter(file_name):\n",
    "    from collections import Counter # can pass in all imports\n",
    "    counter = Counter()\n",
    "    with open(file_name) as f:\n",
    "        for line in f:\n",
    "            counter.update(line.lower().split())\n",
    "        return counter\n",
    "\n",
    "num_pieces = 5\n",
    "!split --number=l/{num_pieces} encyclopedia_britannica.txt temp_file.\n",
    "\n",
    "global_counter2 = Counter()\n",
    "    \n",
    "file_names = glob(\"/Users/Eugene/Desktop/Repos/ipyparallel-vs-MRJob/temp_file*\")\n",
    "async = word_counter.map(file_names) # need to write map\n",
    "\n",
    "for engine_result in async:\n",
    "    global_counter2.update(engine_result)\n",
    "    \n",
    "!rm temp_file*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_counter1 == global_counter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-27 18:58:59.753 [IPClusterStop] Removing pid file: C:\\Users\\Eugene\\.ipython\\profile_default\\pid\\ipcluster.pid\n"
     ]
    }
   ],
   "source": [
    "!ipcluster stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRJob Version of Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mr_word_counter.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mr_word_counter.py\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "\n",
    "class MRWordFrequencyCount(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        for word in line.lower().split():\n",
    "            yield (word, 1)\n",
    "\n",
    "    def combiner(self, word, aggregated_counts):\n",
    "        yield word, sum(aggregated_counts)\n",
    "\n",
    "    def reducer(self, key, count):\n",
    "        yield key, sum(count)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRWordFrequencyCount.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory c:\\users\\eugene\\appdata\\local\\temp\\mr_word_counter.Eugene.20170827.235900.359000\n",
      "Running step 1 of 1...\n",
      "reading from STDIN\n",
      "Streaming final output from c:\\users\\eugene\\appdata\\local\\temp\\mr_word_counter.Eugene.20170827.235900.359000\\output...\n",
      "Removing temp directory c:\\users\\eugene\\appdata\\local\\temp\\mr_word_counter.Eugene.20170827.235900.359000...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"the\"\t693015\n",
      "\"of\"\t424805\n",
      "\"and\"\t247850\n",
      "\"in\"\t214955\n",
      "\"to\"\t173425\n",
      "\"a\"\t155675\n",
      "\"is\"\t102865\n",
      "\"by\"\t81345\n",
      "\"was\"\t70005\n",
      "\"as\"\t58580\n",
      "\"on\"\t51990\n",
      "\"which\"\t51645\n",
      "\"it\"\t51545\n",
      "\"with\"\t50830\n",
      "\"for\"\t50715\n",
      "\"at\"\t48265\n",
      "\"that\"\t47875\n",
      "\"his\"\t46175\n",
      "\"from\"\t46035\n",
      "\"are\"\t45785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sort: write failed: 'standard output'\n",
      "sort: write error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python mr_word_counter.py < encyclopedia_britannica.txt > temp_encyclopedia_counter_results.txt\n",
    "\n",
    "# sort by second key in reverse order\n",
    "!cat temp_encyclopedia_counter_results.txt | sort --key 2nr -n | head -20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparision of ipyparallel, MRJob, Manual Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 693015), ('of', 424805), ('and', 247850), ('in', 214955), ('to', 173425), ('a', 155675), ('is', 102865), ('by', 81345), ('was', 70005), ('as', 58580)]\n"
     ]
    }
   ],
   "source": [
    "# ipyparallel version\n",
    "print(global_counter1.most_common()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 693015), ('of', 424805), ('and', 247850), ('in', 214955), ('to', 173425), ('a', 155675), ('is', 102865), ('by', 81345), ('was', 70005), ('as', 58580)]\n"
     ]
    }
   ],
   "source": [
    "# MRjob version\n",
    "from collections import Counter\n",
    "\n",
    "counter_mrjob = Counter()\n",
    "\n",
    "with open('temp_encyclopedia_counter_results.txt') as f:\n",
    "    for line in f:\n",
    "        word, count = line.strip().split('\\t')\n",
    "        counter_mrjob[word.strip('\"')] = int(count)\n",
    "\n",
    "print(counter_mrjob.most_common()[:10])\n",
    "\n",
    "!rm temp_encyclopedia_counter_results.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 693015), ('of', 424805), ('and', 247850), ('in', 214955), ('to', 173425), ('a', 155675), ('is', 102865), ('by', 81345), ('was', 70005), ('as', 58580)]\n",
      "Wall time: 6.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "counter_manual = Counter()\n",
    "with open('encyclopedia_britannica.txt') as f:\n",
    "    for line in f:\n",
    "        counter_manual.update(line.lower().split())\n",
    "\n",
    "print(counter_manual.most_common()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[('\"', 9710), ('the\"', 2730), ('(\"', 995), ('\\\\\\\\ith', 820), ('\\xc2\\xb7', 745), ('\"the', 650), ('\"),', 595), ('\\'\"', 475), ('and\"', 465), ('/', 425)]\n"
     ]
    }
   ],
   "source": [
    "print(global_counter1 == counter_manual) # perfect!\n",
    "print(counter_manual - counter_mrjob).most_common()[:10] # close enough!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "For this word count example, it appears that ipyparallel is significantly faster (8x) than MRJob. Based on the CPU utilization fron `htop`, ipyparallel uses CPUs heavier than MRJob. Hence, I believe that MRJob is not using maximum CPU power. However, ipyparallel is only slightly faster than manual word counter (single CPU process)...  \n",
    "Perhaps, this file is not large enough to merit multiple processors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
